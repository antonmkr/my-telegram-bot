import logging
import asyncio
import random
import requests
import openai
from telegram import Bot
from praw import Reddit
import os
from dotenv import load_dotenv

# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
client = openai.Client()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
REDDIT_CLIENT_ID = os.getenv("REDDIT_CLIENT_ID")
REDDIT_CLIENT_SECRET = os.getenv("REDDIT_CLIENT_SECRET")

CHANNEL_ID = "@gachistocks"
openai.api_key = OPENAI_API_KEY

# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API Reddit
reddit = Reddit(
    client_id=REDDIT_CLIENT_ID,
    client_secret=REDDIT_CLIENT_SECRET,
    user_agent="MyTelegramBot/0.1 by defiler16",
)

# üîπ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
NEWS_SOURCES = {
    "Yahoo Finance": "https://finance.yahoo.com/rss/topstories",
    "BBC News": "http://feeds.bbci.co.uk/news/rss.xml",
    "TechCrunch": "https://techcrunch.com/feed/",
    "Crypto News": "https://cryptonews.com/news/feed/",
    "CNBC": "https://www.cnbc.com/id/100003114/device/rss/rss.html",
    "Bloomberg": "https://www.bloomberg.com/feeds/podcast.xml",
    "Wall Street Journal": "https://feeds.a.dj.com/rss/RSSMarketsMain.xml",
    "Investing.com": "https://www.investing.com/rss/news.rss",
    "Forbes": "https://www.forbes.com/investing/feed/",
    "Financial Times": "https://www.ft.com/rss/home",
    "MarketWatch": "https://www.marketwatch.com/rss/topstories",
    "The Economist": "https://www.economist.com/latest/rss.xml"
}

# üîπ –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π
def fetch_latest_news():
    news_list = []
    for source, url in NEWS_SOURCES.items():
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            from xml.etree import ElementTree as ET
            root = ET.fromstring(response.text)
            items = root.findall(".//item")[:5]

            for item in items:
                title = item.find("title").text.strip()
                news_list.append(title[:120] + "..." if len(title) > 120 else title)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π —Å {source}: {e}")
    return news_list

# üîπ –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ —Å Reddit
def fetch_reddit_posts(subreddits, limit=5):
    posts = []
    try:
        for subreddit in subreddits:
            for submission in reddit.subreddit(subreddit).hot(limit=limit):
                if not submission.over_18:
                    title = submission.title.strip()
                    posts.append(title[:120] + "..." if len(title) > 120 else title)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ —Å Reddit: {e}")
    return posts

# üîπ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è AI-—Ç–µ–∫—Å—Ç–∞
def generate_ai_text(prompt, use_gpt4=False):
    model = "gpt-4-turbo" if use_gpt4 else "gpt-3.5-turbo"
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "–¢—ã –≤–µ–¥–µ—à—å Telegram-–∫–∞–Ω–∞–ª. –ü–∏—à–∏ –∂–∏–≤–æ, –¥–æ–±–∞–≤–ª—è–π –∏–Ω—Å–∞–π–¥—ã, –¥–µ–ª–∞–π –ø–æ—Å—Ç—ã –≤–æ–≤–ª–µ–∫–∞—é—â–∏–º–∏."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1200
        )
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ AI: {e}")
        return "ü§ñ –û—à–∏–±–∫–∞ AI. –û–±—Å—É–¥–∏–º –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö!"

# üîπ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–µ–º –¥–ª—è AI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏
finance_topics = [
    "–õ—É—á—à–∏–µ —Å–ø–æ—Å–æ–±—ã –ø–∞—Å—Å–∏–≤–Ω–æ–≥–æ –¥–æ—Ö–æ–¥–∞ –≤ 2025 –≥–æ–¥—É",
    "–ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ —Å–µ–±—è?",
    "–ö–∞–∫–∏–µ –∞–∫—Ç–∏–≤—ã –∑–∞—â–∏—â–∞—é—Ç –¥–µ–Ω—å–≥–∏ –æ—Ç –∏–Ω—Ñ–ª—è—Ü–∏–∏?",
    "–ö–∞–∫ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∏—Å–∫–∏ –ø—Ä–∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è—Ö?",
    "–û—à–∏–±–∫–∏ –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ –∏ –∫–∞–∫ –∏—Ö –∏–∑–±–µ–∂–∞—Ç—å",
    "–ë—É–¥—É—â–µ–µ —Ñ–æ–Ω–¥–æ–≤–æ–≥–æ —Ä—ã–Ω–∫–∞: –∫–∞–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã —É—á–∏—Ç—ã–≤–∞—Ç—å?",
    "–ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—å?",
    "–°—Ç–æ–∏—Ç –ª–∏ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—É?",
    "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—è –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –∫–∞–∫ –Ω–µ –ø–æ–¥–¥–∞–≤–∞—Ç—å—Å—è –ø–∞–Ω–∏–∫–µ?",
    "–õ—É—á—à–∏–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ 2025 –≥–æ–¥–∞"
]

def generate_finance_tips():
    return generate_ai_text(f"–î–∞–π —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —Å–æ–≤–µ—Ç –ø–æ —Ç–µ–º–µ: {random.choice(finance_topics)}", use_gpt4=True)

# üîπ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ AI-—Ñ—É–Ω–∫—Ü–∏–∏
def generate_market_analysis():
    return generate_ai_text("–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä —Ñ–æ–Ω–¥–æ–≤–æ–≥–æ —Ä—ã–Ω–∫–∞ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è: –∏–Ω–¥–µ–∫—Å—ã, —Ç—Ä–µ–Ω–¥—ã, –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã.", use_gpt4=True)

def generate_crypto_trends():
    return generate_ai_text("–û–±–∑–æ—Ä —Å–≤–µ–∂–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤ –≤ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–µ: —Ç–æ–ø–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã, –ø—Ä–æ–≥–Ω–æ–∑—ã, –∏–Ω—Å–∞–π–¥—ã.", use_gpt4=True)

def generate_investment_hacks():
    return generate_ai_text("–ü–æ–¥–µ–ª–∏—Å—å —Ç–æ–ø–æ–≤—ã–º–∏ –ª–∞–π—Ñ—Ö–∞–∫–∞–º–∏ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–∞–ª–æ –∫—Ç–æ –∑–Ω–∞–µ—Ç.", use_gpt4=True)

def generate_real_estate_tips():
    return generate_ai_text("–ö–∞–∫–∏–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –±—É–¥—É—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã –≤ 2025 –≥–æ–¥—É?", use_gpt4=True)

# üîπ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
content_choices = [
    "news", "reddit", "finance_tips", "crypto_insights", "business_strategies",
    "market_analysis", "crypto_trends", "investment_hacks", "real_estate_tips"
]

# üîπ –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
def clean_and_format_text(text):
    text = text.replace("\n\n", "\n")
    text = text.replace("ü§ñ", "üìä")
    return text[:990] + "..." if len(text) > 1000 else text

async def send_post(bot, text):
    try:
        formatted_text = clean_and_format_text(text)
        await bot.send_message(chat_id=CHANNEL_ID, text=formatted_text, parse_mode="HTML")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ—Å—Ç–∞: {e}")

# üîπ –ê–ª–≥–æ—Ä–∏—Ç–º –≤—ã–±–æ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
async def create_and_post_content(bot):
    while True:
        logger.info("üì¢ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è AI-–∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
        content_type = random.choices(content_choices, weights=[3, 3, 3, 2, 2, 2, 2, 2, 1], k=1)[0]

        if content_type == "news":
            latest_news = fetch_latest_news()
            if latest_news:
                await send_post(bot, generate_ai_text(f"–†–∞–∑–±–µ—Ä–∏ –Ω–æ–≤–æ—Å—Ç—å –∫—Ä–∞—Ç–∫–æ: {random.choice(latest_news)}", use_gpt4=True))

        elif content_type == "reddit":
            reddit_posts = fetch_reddit_posts(["stocks", "technology", "crypto", "finance", "economy", "wallstreetbets"], limit=5)
            if reddit_posts:
                await send_post(bot, generate_ai_text(f"–†–∞–∑–±–µ—Ä–∏ Reddit-–ø–æ—Å—Ç: {random.choice(reddit_posts)}", use_gpt4=False))

        elif content_type == "finance_tips":
            await send_post(bot, generate_finance_tips())

        elif content_type == "crypto_insights":
            await send_post(bot, generate_crypto_trends())

        elif content_type == "market_analysis":
            await send_post(bot, generate_market_analysis())

        delay = random.randint(1800, 7200)
        logger.info(f"‚è≥ –°–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç —á–µ—Ä–µ–∑ {delay // 60} –º–∏–Ω—É—Ç.")
        await asyncio.sleep(delay)

# üîπ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    bot = Bot(TELEGRAM_TOKEN)
    logger.info("üöÄ AI-–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    await create_and_post_content(bot)

if __name__ == "__main__":
    asyncio.run(main())
